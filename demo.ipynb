{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial Age Estimator Example\n",
    "In this simple example, we show how the [MAX-Facial-Age-Estimator](https://developer.ibm.com/exchanges/models/all/max-facial-age-estimator/) model can be used to detect human faces in an image and predict the ages of each face. Additionally, we show how to use the returned bounding box coordinates for each face to visualize the bounding boxes and the age predictions on the original input image.\n",
    "\n",
    "## Setup\n",
    "The notebook calls the MAX Facial Age Estimator microservice, which must be running.  You can either use the [hosted demo instance](http://max-facial-age-estimator.max.us-south.containers.appdomain.cloud), or follow the instructions for [deploying the microservice locally from the Dockerhub image](https://github.com/IBM/MAX-Facial-Age-Estimator#deploy-from-docker-hub)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook requires matplotlib, Pillow and requests\n",
    "# You only need to run the line below to install these if you don't already have them installed\n",
    "\n",
    "! pip install -q matplotlib Pillow requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This url must point to a running instance of the model microservice\n",
    "# By default this assumes you are using the hosted demo instance:\n",
    "\n",
    "url = 'http://max-facial-age-estimator.max.us-south.containers.appdomain.cloud/model/predict'\n",
    "# Comment the line above and uncomment the following line if you are running the model microservice locally\n",
    "# url = 'http://localhost:5000/model/predict'\n",
    "\n",
    "def call_model(input_img):\n",
    "    \"\"\"\n",
    "    Takes in input image file path and generates face bboxes and ages.\n",
    "    \"\"\"\n",
    "    files = {'image': ('image.jpg',open(input_img,'rb'), 'images/jpeg')}\n",
    "    r = requests.post(url, files=files).json()\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Visualizing the test image\n",
    "First we load the image with Pillow and display the image in our notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, load the image with Pillow and display the image in our notebook\n",
    "img_path = 'assets/tom_cruise.jpg'\n",
    "image = Image.open(img_path)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Call Model to detect faces and predict ages for each face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the facial age estimator model\n",
    "model_response = call_model(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualize model response\n",
    "The model returns JSON containing a predictions field which is an array of JSON objects, one for each face detected in the image. For each face, the bounding box coordinates are contained in the `detection_box` field, while the age estimated results are contained in the `age_estimation` field.\n",
    "\n",
    "The bounding box coordinates are given in the format [xmin, ymin, width, height], i.e., height for y and width for x. \n",
    "We use these pixel coordinates to overlay the bounding boxes on the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the model results\n",
    "import json\n",
    "print(json.dumps(model_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image height and width\n",
    "image_width, image_height = image.size\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots()\n",
    "# Set larger figure size\n",
    "fig.set_dpi(600)\n",
    "# Display the image\n",
    "plt.imshow(image)\n",
    "\n",
    "# Set up the color of the bounding boxes and age text\n",
    "color = '#00FF00'\n",
    "# For each face, draw the bounding box and predicted age\n",
    "for prediction in model_response['predictions']:\n",
    "    bbox = prediction['detection_box']    \n",
    "    # Unpack the coordinate values\n",
    "    y1, x1, y2, x2 = bbox\n",
    "    # Map the normalized coordinates to pixel values: scale by image height for 'y' and image width for 'x'\n",
    "    y1 *= image_height\n",
    "    y2 *= image_height\n",
    "    x1 *= image_width\n",
    "    x2 *= image_width        \n",
    "    age_label = 'Estimated age: {}'.format(prediction['age_estimation'])\n",
    "    # Create the bounding box rectangle - we need the base point (x, y) and the width and height of the rectangle\n",
    "    rectangle = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=1, edgecolor=color, facecolor='none')\n",
    "    ax.add_patch(rectangle)\n",
    "    # Plot the bounding box and the estimated age\n",
    "    plt.text(x1, y1-5 , age_label, fontsize=4, color=color, fontweight='bold')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
